{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - INRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## FakeNewsCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1a09b-98b9-4c78-9617-cd6829d2cfc7",
   "metadata": {},
   "source": [
    "[FakeNewsCorpus](https://github.com/several27/FakeNewsCorpus) is mainly intended for use in training deep learning algorithms for purpose of fake news recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ccb1c-1dc7-44cf-8120-a433cbc19915",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eade79cc-3483-441c-9dca-a342df32a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e5dfa-bdad-47f4-8a29-7210c2b565d4",
   "metadata": {},
   "source": [
    "## Sampling the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1558ccb-d87c-47f5-bcef-5b30eba6c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set (216,212,648 rows)\n",
    "data_set = 'news_cleaned_2018_02_13.csv'\n",
    "\n",
    "# Defining the number of rows to be sampled\n",
    "number_of_rows = 100\n",
    "\n",
    "# Creating a directory to store output files\n",
    "output_dir = 'fakenewscorpus_sample'\n",
    "output_file_key = 'news_cleaned_sample' # The output file will have this key plus a suffix\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Explicitly defining data types for all columns as 'str'\n",
    "column_data_types = {\n",
    "    'id': str,\n",
    "    'domain': str,\n",
    "    'type': str,\n",
    "    'url': str,\n",
    "    'content': str,\n",
    "    'scraped_at': str,\n",
    "    'inserted_at': str,\n",
    "    'updated_at': str,\n",
    "    'title': str,\n",
    "    'authors': str,\n",
    "    'keywords': str,\n",
    "    'meta_keywords': str,\n",
    "    'meta_description': str,\n",
    "    'tags': str,\n",
    "    'summary': str,\n",
    "    'source': str\n",
    "}\n",
    "\n",
    "# Use the 'read_csv' function to sample\n",
    "df_sample = pd.read_csv(data_set, encoding='utf-8', nrows=number_of_rows, dtype=column_data_types)\n",
    "filename = f'{output_dir}/{output_file_key}.csv'\n",
    "df_sample.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb52c16-71ec-4f53-bfa2-1e9736883ade",
   "metadata": {},
   "source": [
    "## Extracting texts classified as `fake` from the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58312d07-6b09-4881-aa38-26da9734b610",
   "metadata": {},
   "source": [
    "A `DtypeWarning` related to column (0) occurs because the column cannot be explicitly defined as `str` due to the fact that it is actually unnamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0346e3d-5725-4d93-b088-f3f032d8576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyamr\\AppData\\Local\\Temp\\ipykernel_22540\\2208234334.py:30: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_set, encoding='utf-8', dtype=column_data_types)\n"
     ]
    }
   ],
   "source": [
    "# Defining the data set (216,212,648 rows)\n",
    "data_set = 'news_cleaned_2018_02_13.csv'\n",
    "\n",
    "# Creating a directory to store output files\n",
    "output_dir = 'fakenewscorpus'\n",
    "output_file_key = 'news_cleaned_fake'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "filename = f'{output_dir}/{output_file_key}.csv'\n",
    "\n",
    "# Explicitly defining data types for all columns as 'str'\n",
    "column_data_types = {\n",
    "    'id': str,\n",
    "    'domain': str,\n",
    "    'type': str,\n",
    "    'url': str,\n",
    "    'content': str,\n",
    "    'scraped_at': str,\n",
    "    'inserted_at': str,\n",
    "    'updated_at': str,\n",
    "    'title': str,\n",
    "    'authors': str,\n",
    "    'keywords': str,\n",
    "    'meta_keywords': str,\n",
    "    'meta_description': str,\n",
    "    'tags': str,\n",
    "    'summary': str,\n",
    "    'source': str\n",
    "}\n",
    "\n",
    "# Importing the data set into a dataframe and extracting the 'fake' texts\n",
    "df = pd.read_csv(data_set, encoding='utf-8', dtype=column_data_types)\n",
    "df_fake = df[df['type'] == 'fake']\n",
    "df_fake.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a2164-bade-40b7-a2e0-54158b67654d",
   "metadata": {},
   "source": [
    "## Importing the `fake` texts into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9528e69-6ef6-4579-a616-d4e131a4c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set of 'fake' texts\n",
    "output_dir = 'fakenewscorpus'\n",
    "output_file_key = 'news_cleaned_fake'\n",
    "filename = f'{output_dir}/{output_file_key}.csv'\n",
    "data_set_fake = filename\n",
    "\n",
    "# Explicitly defining data types for all columns as 'str'\n",
    "column_data_types = {\n",
    "    'Unnamed: 0': str,\n",
    "    'id': str,\n",
    "    'domain': str,\n",
    "    'type': str,\n",
    "    'url': str,\n",
    "    'content': str,\n",
    "    'scraped_at': str,\n",
    "    'inserted_at': str,\n",
    "    'updated_at': str,\n",
    "    'title': str,\n",
    "    'authors': str,\n",
    "    'keywords': str,\n",
    "    'meta_keywords': str,\n",
    "    'meta_description': str,\n",
    "    'tags': str,\n",
    "    'summary': str,\n",
    "    'source': str\n",
    "}\n",
    "\n",
    "# Importing the 'fake' texts into a dataframe\n",
    "df_fake = pd.read_csv(data_set_fake, encoding='utf-8', dtype=column_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab015a8-7ec9-42fd-a259-5ee54aa9100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          object\n",
       "id                  object\n",
       "domain              object\n",
       "type                object\n",
       "url                 object\n",
       "content             object\n",
       "scraped_at          object\n",
       "inserted_at         object\n",
       "updated_at          object\n",
       "title               object\n",
       "authors             object\n",
       "keywords            object\n",
       "meta_keywords       object\n",
       "meta_description    object\n",
       "tags                object\n",
       "summary             object\n",
       "source              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8cc0edc-2550-4843-ab26-33988efdf6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/opinion-conservative/...</td>\n",
       "      <td>Headline: Bitcoin &amp; Blockchain Searches Exceed...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n",
       "      <td>The Pirate'S Cove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/politics/2018/01/wate...</td>\n",
       "      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/politics/2018/01/vete...</td>\n",
       "      <td>Veteran Commentator Calls Out the Growing “Eth...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Veteran Commentator Calls Out the Growing “Eth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/arts/2018/01/lost-wor...</td>\n",
       "      <td>Lost Words, Hidden Words, Otters, Banks and Bo...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Lost Words, Hidden Words, Otters, Banks and Books</td>\n",
       "      <td>Jackie Morris Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>Red Alert: Bond Yields Are SCREAMING “Inflatio...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Red Alert: Bond Yields Are SCREAMING “Inflatio...</td>\n",
       "      <td>Phoenix Capital Research</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  id             domain  type  \\\n",
       "0         27  34  beforeitsnews.com  fake   \n",
       "1         28  35  beforeitsnews.com  fake   \n",
       "2         29  36  beforeitsnews.com  fake   \n",
       "3         30  37  beforeitsnews.com  fake   \n",
       "4         31  38  beforeitsnews.com  fake   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://beforeitsnews.com/opinion-conservative/...   \n",
       "1  http://beforeitsnews.com/politics/2018/01/wate...   \n",
       "2  http://beforeitsnews.com/politics/2018/01/vete...   \n",
       "3  http://beforeitsnews.com/arts/2018/01/lost-wor...   \n",
       "4  http://beforeitsnews.com/financial-markets/201...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Headline: Bitcoin & Blockchain Searches Exceed...   \n",
       "1  Water Cooler 1/25/18 Open Thread; Fake News ? ...   \n",
       "2  Veteran Commentator Calls Out the Growing “Eth...   \n",
       "3  Lost Words, Hidden Words, Otters, Banks and Bo...   \n",
       "4  Red Alert: Bond Yields Are SCREAMING “Inflatio...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-02 01:19:41.756664   \n",
       "1  2018-02-02 01:19:41.756664   \n",
       "2  2018-02-02 01:19:41.756664   \n",
       "3  2018-02-02 01:19:41.756664   \n",
       "4  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                               title  \\\n",
       "0  Surprise: Socialist Hotbed Of Venezuela Has Lo...   \n",
       "1  Water Cooler 1/25/18 Open Thread; Fake News ? ...   \n",
       "2  Veteran Commentator Calls Out the Growing “Eth...   \n",
       "3  Lost Words, Hidden Words, Otters, Banks and Books   \n",
       "4  Red Alert: Bond Yields Are SCREAMING “Inflatio...   \n",
       "\n",
       "                    authors keywords meta_keywords meta_description tags  \\\n",
       "0         The Pirate'S Cove      NaN          ['']              NaN  NaN   \n",
       "1                       NaN      NaN          ['']              NaN  NaN   \n",
       "2                       NaN      NaN          ['']              NaN  NaN   \n",
       "3      Jackie Morris Artist      NaN          ['']              NaN  NaN   \n",
       "4  Phoenix Capital Research      NaN          ['']              NaN  NaN   \n",
       "\n",
       "  summary source  \n",
       "0     NaN    NaN  \n",
       "1     NaN    NaN  \n",
       "2     NaN    NaN  \n",
       "3     NaN    NaN  \n",
       "4     NaN    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22698720-7db5-483b-9c62-869366040ed8",
   "metadata": {},
   "source": [
    "### Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29cfc0a-4967-4453-adf8-56523aca0375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:Red Alert: Bond Yields Are SCREAMING “Inflation is coming!”\n",
      "\n",
      "Headline: Bitcoin & Blockchain Searches Exceed Trump! Blockchain Stocks Are Next!\n",
      "\n",
      "Love it, or hate it, the $USD is the reserve currency of the world. So what happens to it is of MASSIVE import to the rest of the financial system. With that in mind, take a look at the below chart. This is looking more and more like a “false breakout.” False breakouts are dangerous\n",
      "\n",
      "The post Red Alert: Bond Yields Are SCREAMING “Inflation is coming!” appeared first on Gains Pains & Capital.\n",
      "\n",
      "Source: http://gainspainscapital.com/2018/01/25/red-alert-bond-yields-screaming-inflation-coming/\n",
      "title:Red Alert: Bond Yields Are SCREAMING “Inflation is coming!”\n",
      "authors:Phoenix Capital Research\n"
     ]
    }
   ],
   "source": [
    "inspected_row = 4\n",
    "print('content:' + df_fake.loc[inspected_row, 'content'])\n",
    "print('title:' + df_fake.loc[inspected_row, 'title'])\n",
    "print('authors:' + df_fake.loc[inspected_row, 'authors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07f191-4e64-4048-a9a5-eb2a780b2796",
   "metadata": {},
   "source": [
    "## Exporting the `fake` texts dataframe to a JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68c5a4f8-aff1-46ea-aada-6405562bc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set of 'fake' texts\n",
    "output_dir = 'fakenewscorpus'\n",
    "output_file_key = 'news_cleaned_fake'\n",
    "filename_jsonl = f'{output_dir}/{output_file_key}.jsonl'\n",
    "\n",
    "df_fake.to_json(filename_jsonl, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c0796-ef36-467f-a015-0a8fa46e6c19",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be542b-a25c-4c44-96d6-f1ba553c7a37",
   "metadata": {},
   "source": [
    "### Partitioning the data set into smaller chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3b11b-a9fa-49c1-98a5-edc273ff9831",
   "metadata": {},
   "source": [
    "Even though this piece of code is consistent, the partitioning fails due to unknown reasons. It may be useful as a starting point in a future attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7dda5-407d-476d-b57c-b7e2d0371397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set (216,212,648 rows)\n",
    "data_set = 'news_cleaned_2018_02_13.csv'\n",
    "\n",
    "# Defining the chunk size\n",
    "chunk_size = 1000000  # This will create chunks of 1,000,000 rows\n",
    "\n",
    "# Creating a directory to store output files\n",
    "output_dir = 'fakenewscorpus'\n",
    "output_file_key = 'news_cleaned'  # The output files will have the same key plus a suffix\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Explicitly defining data types for all columns as 'str'\n",
    "column_data_types = {\n",
    "    'id': str,\n",
    "    'domain': str,\n",
    "    'type': str,\n",
    "    'url': str,\n",
    "    'content': str,\n",
    "    'scraped_at': str,\n",
    "    'inserted_at': str,\n",
    "    'updated_at': str,\n",
    "    'title': str,\n",
    "    'authors': str,\n",
    "    'keywords': str,\n",
    "    'meta_keywords': str,\n",
    "    'meta_description': str,\n",
    "    'tags': str,\n",
    "    'summary': str,\n",
    "    'source': str\n",
    "}\n",
    "\n",
    "# Using the 'read_csv' function with 'iterator' and 'chunksize' parameters\n",
    "reader = pd.read_csv(data_set, encoding='utf-8', iterator=True, chunksize=chunk_size, dtype=column_data_types)\n",
    "\n",
    "i = 0\n",
    "for chunk in reader:\n",
    "    # Filter rows where 'tags' equals 'fake'\n",
    "    filtered_chunk = chunk[chunk['type'] == 'fake']\n",
    "    \n",
    "    filename = f'{output_dir}/{output_file_key}{i+1:02d}.csv'\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(timestamp, ': Processing ' + filename)\n",
    "    filtered_chunk.to_csv(filename, index=False)\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(timestamp, ': Processed ' + filename)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f2a3a-b9b5-4ffe-a8a5-982df993adbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
