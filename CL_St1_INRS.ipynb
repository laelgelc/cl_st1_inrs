{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - INRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## FakeNewsCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1a09b-98b9-4c78-9617-cd6829d2cfc7",
   "metadata": {},
   "source": [
    "[FakeNewsCorpus](https://github.com/several27/FakeNewsCorpus) is mainly intended for use in training deep learning algorithms for purpose of fake news recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ccb1c-1dc7-44cf-8120-a433cbc19915",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eade79cc-3483-441c-9dca-a342df32a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be542b-a25c-4c44-96d6-f1ba553c7a37",
   "metadata": {},
   "source": [
    "## Partitioning the data set into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12478ef-4a75-418b-a9dd-f18276941c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data set (216,212,648 rows)\n",
    "data_set = 'news_cleaned_2018_02_13.csv'\n",
    "\n",
    "# Defining the chunk size\n",
    "chunk_size = 7207089  # This will create chunks of 7,207,089 rows, enabling the data set to be partitioned into 30 chunks\n",
    "\n",
    "# Creating a directory to store output files\n",
    "output_dir = 'fakenewscorpus'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Use the 'read_csv' function with 'iterator' and 'chuncksize' parameters\n",
    "reader = pd.read_csv(data_set, encoding='utf-8', iterator=True, chunksize=chunk_size)\n",
    "\n",
    "i = 0\n",
    "for chunk in reader:\n",
    "    filename = f'{output_dir}/news_cleaned{i+1:02d}.csv'\n",
    "    chunk.to_csv(filename, index=False)\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
